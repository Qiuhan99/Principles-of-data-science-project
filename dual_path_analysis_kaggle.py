"""
åŒè·¯å¾„é±¼ç±»åˆ†ç±»æ¨¡å‹åˆ†æè„šæœ¬ - Kaggleç‰ˆæœ¬
é€‚é…Kaggleç¯å¢ƒçš„ç‰ˆæœ¬ï¼Œè‡ªåŠ¨å¤„ç†è·¯å¾„å’ŒGPU

Kaggleä½¿ç”¨è¯´æ˜:
1. å°†æ•°æ®é›†æ·»åŠ åˆ°Notebookçš„Inputä¸­
2. æ•°æ®é›†è·¯å¾„é€šå¸¸åœ¨ /kaggle/input/dataset-name/
3. è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨ /kaggle/working/
"""

import json
import os
import glob
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from transformers import SwinModel, SwinConfig
import matplotlib.pyplot as plt

# è®¾ç½®ç±»åˆ«
CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']
NUM_CLASSES = len(CLASSES)

# Kaggleç¯å¢ƒæ£€æµ‹
IN_KAGGLE = os.path.exists('/kaggle/input')
if IN_KAGGLE:
    BASE_DIR = '/kaggle/working'
    INPUT_DIR = '/kaggle/input'
    WORKING_DIR = '/kaggle/working'
    print("=" * 60)
    print("æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
    print(f"è¾“å…¥ç›®å½•: {INPUT_DIR}")
    print(f"å·¥ä½œç›®å½•: {WORKING_DIR}")
    print("=" * 60)
else:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    INPUT_DIR = BASE_DIR
    WORKING_DIR = BASE_DIR
    print("æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨å½“å‰ç›®å½•")


class FishDataset(Dataset):
    """é±¼ç±»æ•°æ®é›†ç±»ï¼Œæ”¯æŒå…¨å±€å’Œå±€éƒ¨è·¯å¾„"""
    
    def __init__(self, data_dir: str, json_files: List[str], transform=None, expand_ratio=0.2, skip_missing=True):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•
            json_files: JSONæ ‡æ³¨æ–‡ä»¶åˆ—è¡¨
            transform: å›¾åƒå˜æ¢
            expand_ratio: BBoxæ‰©å±•æ¯”ä¾‹ï¼ˆé»˜è®¤20%ï¼‰
            skip_missing: æ˜¯å¦è·³è¿‡ç¼ºå¤±çš„å›¾ç‰‡ï¼ˆé»˜è®¤Trueï¼‰
        """
        self.data_dir = data_dir
        self.transform = transform
        self.expand_ratio = expand_ratio
        self.skip_missing = skip_missing
        self.samples = []
        
        # åŠ è½½æ‰€æœ‰æ ‡æ³¨æ•°æ®
        for json_file in json_files:
            if not os.path.exists(json_file):
                print(f"è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {json_file}")
                continue
                
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for item in data:
                    filename = item['filename']
                    annotations = item['annotations']
                    
                    # è·å–å›¾ç‰‡çš„ç±»åˆ«ï¼ˆä»ç¬¬ä¸€ä¸ªæ ‡æ³¨æˆ–æ–‡ä»¶åæ¨æ–­ï¼‰
                    if annotations:
                        label = CLASSES.index(annotations[0]['class'])
                    else:
                        # å¦‚æœæ²¡æ ‡æ³¨ï¼Œä»æ–‡ä»¶åæ¨æ–­
                        for cls in CLASSES:
                            if cls in filename:
                                label = CLASSES.index(cls)
                                break
                        else:
                            continue
                    
                    # å­˜å‚¨æ¯ä¸ªæ ‡æ³¨æ¡†ä½œä¸ºä¸€ä¸ªæ ·æœ¬
                    for ann in annotations:
                        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆé¢„æ£€æŸ¥ï¼‰
                        img_path = os.path.join(self.data_dir, filename)
                        if not os.path.exists(img_path):
                            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„ï¼ˆKaggleé€‚é…ï¼‰
                            img_name = os.path.basename(filename)
                            possible_paths = [
                                img_path,
                                os.path.join(self.data_dir, img_name),
                                os.path.join(BASE_DIR, img_name),
                                os.path.join(BASE_DIR, filename),
                                # Kaggleè¾“å…¥ç›®å½•è·¯å¾„
                                os.path.join(INPUT_DIR, img_name),
                                os.path.join(INPUT_DIR, filename),
                            ]
                            
                            # å°è¯•åœ¨æ‰€æœ‰è¾“å…¥æ•°æ®é›†ä¸­æŸ¥æ‰¾
                            if IN_KAGGLE:
                                for dataset_name in os.listdir(INPUT_DIR):
                                    dataset_path = os.path.join(INPUT_DIR, dataset_name)
                                    if os.path.isdir(dataset_path):
                                        possible_paths.extend([
                                            os.path.join(dataset_path, filename),
                                            os.path.join(dataset_path, img_name),
                                            os.path.join(dataset_path, 'images', filename),
                                            os.path.join(dataset_path, 'images', img_name),
                                        ])
                            
                            found = False
                            for path in possible_paths:
                                if os.path.exists(path):
                                    found = True
                                    break
                            
                            # å¦‚æœskip_missingä¸ºTrueä¸”å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
                            if self.skip_missing and not found:
                                continue
                        
                        self.samples.append({
                            'filename': filename,
                            'label': label,
                            'bbox': {
                                'x': ann['x'],
                                'y': ann['y'],
                                'width': ann['width'],
                                'height': ann['height']
                            }
                        })
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        img_path = os.path.join(self.data_dir, sample['filename'])
        
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(img_path):
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            img_name = os.path.basename(img_path)
            possible_paths = [
                img_path,  # åŸå§‹è·¯å¾„
                os.path.join(self.data_dir, img_name),
                os.path.join(BASE_DIR, img_name),
                os.path.join(BASE_DIR, sample['filename']),
                # Kaggleè¾“å…¥ç›®å½•è·¯å¾„
                os.path.join(WORKING_DIR, img_name),
                os.path.join(WORKING_DIR, sample['filename']),
            ]
            
            # å°è¯•åœ¨æ‰€æœ‰è¾“å…¥æ•°æ®é›†ä¸­æŸ¥æ‰¾
            if IN_KAGGLE:
                for dataset_name in os.listdir(INPUT_DIR):
                    dataset_path = os.path.join(INPUT_DIR, dataset_name)
                    if os.path.isdir(dataset_path):
                        possible_paths.extend([
                            os.path.join(dataset_path, sample['filename']),
                            os.path.join(dataset_path, img_name),
                            os.path.join(dataset_path, 'images', sample['filename']),
                            os.path.join(dataset_path, 'images', img_name),
                        ])
            
            # å¦‚æœæ–‡ä»¶ååŒ…å«ç±»åˆ«ï¼ˆå¦‚ ALB/img_xxx.jpgï¼‰ï¼Œå°è¯•ä¸åŒçš„åŸºç¡€è·¯å¾„
            if '/' in sample['filename']:
                parts = sample['filename'].split('/')
                if len(parts) >= 2:
                    category = parts[0]
                    img_file = parts[-1]
                    # å°è¯•ä¸åŒçš„åŸºç¡€è·¯å¾„
                    base_paths = [
                        self.data_dir,
                        BASE_DIR,
                        INPUT_DIR,
                    ]
                    # æ·»åŠ æ‰€æœ‰è¾“å…¥æ•°æ®é›†è·¯å¾„
                    if IN_KAGGLE:
                        for dataset_name in os.listdir(INPUT_DIR):
                            dataset_path = os.path.join(INPUT_DIR, dataset_name)
                            if os.path.isdir(dataset_path):
                                base_paths.append(dataset_path)
                    
                    for base in base_paths:
                        possible_paths.append(os.path.join(base, category, img_file))
                        possible_paths.append(os.path.join(base, 'images', category, img_file))
                        possible_paths.append(os.path.join(base, img_file))
            
            found = False
            for path in possible_paths:
                if os.path.exists(path):
                    img_path = path
                    found = True
                    break
            
            if not found:
                # å¦‚æœå›¾ç‰‡ä¸å­˜åœ¨ï¼Œåˆ›å»ºå ä½å›¾åƒ
                print(f"è­¦å‘Š: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ {sample['filename']}ï¼Œä½¿ç”¨å ä½å›¾åƒ")
                full_image = Image.new('RGB', (800, 600), color='gray')
        
        # åŠ è½½å®Œæ•´å›¾åƒï¼ˆå…¨å±€è·¯å¾„ï¼‰
        try:
            full_image = Image.open(img_path).convert('RGB')
        except Exception as e:
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½å›¾ç‰‡ {sample['filename']}: {e}")
            return None
        
        # è·å–BBoxå¹¶æ‰©å±•20%
        bbox = sample['bbox']
        x, y, w, h = bbox['x'], bbox['y'], bbox['width'], bbox['height']
        
        # æ‰©å±•BBox
        expand_w = w * self.expand_ratio
        expand_h = h * self.expand_ratio
        x_expanded = max(0, x - expand_w / 2)
        y_expanded = max(0, y - expand_h / 2)
        w_expanded = min(full_image.width - x_expanded, w + expand_w)
        h_expanded = min(full_image.height - y_expanded, h + expand_h)
        
        # è£å‰ªå±€éƒ¨å›¾åƒï¼ˆå±€éƒ¨è·¯å¾„ï¼‰
        local_image = full_image.crop((
            int(x_expanded),
            int(y_expanded),
            int(x_expanded + w_expanded),
            int(y_expanded + h_expanded)
        ))
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            try:
                full_image = self.transform(full_image)
                local_image = self.transform(local_image)
            except Exception as e:
                print(f"è­¦å‘Š: å›¾åƒå˜æ¢å¤±è´¥ {sample['filename']}: {e}")
                return None
        
        label = sample['label']
        
        return {
            'full_image': full_image,
            'local_image': local_image,
            'label': label,
            'filename': sample['filename']
        }


class SwinBackbone(nn.Module):
    """Swin Transformer Backbone"""
    
    def __init__(self, model_name='microsoft/swin-tiny-patch4-window7-224'):
        super().__init__()
        config = SwinConfig.from_pretrained(model_name)
        self.swin = SwinModel.from_pretrained(model_name, config=config)
        # Swin-tinyçš„embed_dimæ˜¯96ï¼Œä½†éœ€è¦æ£€æŸ¥å®é™…è¾“å‡ºç»´åº¦
        self.feature_dim = config.embed_dim * (config.depths[-1] // config.num_layers) if hasattr(config, 'depths') else config.embed_dim
        
        # å®é™…æµ‹è¯•è¾“å‡ºç»´åº¦
        # SwinModelçš„è¾“å‡ºæ˜¯BaseModelOutputï¼Œlast_hidden_stateçš„å½¢çŠ¶æ˜¯ [batch, num_patches, embed_dim]
        # éœ€è¦å…¨å±€å¹³å‡æ± åŒ–å¾—åˆ° [batch, embed_dim]
        # å¯¹äºswin-tiny: embed_dim = 96
        
    def forward(self, x):
        outputs = self.swin(x)
        # SwinModelè¿”å›BaseModelOutputï¼ŒåŒ…å«last_hidden_state
        # last_hidden_stateå½¢çŠ¶: [batch_size, num_patches, embed_dim]
        # éœ€è¦å…¨å±€å¹³å‡æ± åŒ–: [batch_size, embed_dim]
        if hasattr(outputs, 'last_hidden_state'):
            # å¯¹åºåˆ—ç»´åº¦ï¼ˆnum_patchesï¼‰è¿›è¡Œå¹³å‡æ± åŒ–
            features = outputs.last_hidden_state.mean(dim=1)  # [batch, embed_dim]
            return features
        elif hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:
            return outputs.pooler_output
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•è·å–ç¬¬ä¸€ä¸ªè¾“å‡º
            if isinstance(outputs, tuple) and len(outputs) > 0:
                return outputs[0].mean(dim=1)
            else:
                raise ValueError("æ— æ³•ä»SwinModelè·å–ç‰¹å¾")


class DualPathModel(nn.Module):
    """åŒè·¯å¾„æ¨¡å‹ï¼šå…¨å±€è·¯å¾„ + å±€éƒ¨è·¯å¾„"""
    
    def __init__(self, num_classes=NUM_CLASSES):
        super().__init__()
        
        # å…±äº«çš„Swin Backbone
        self.global_backbone = SwinBackbone()
        self.local_backbone = SwinBackbone()
        
        # åŠ¨æ€è·å–ç‰¹å¾ç»´åº¦ï¼ˆé€šè¿‡å‰å‘ä¼ æ’­æµ‹è¯•ï¼‰
        # åˆ›å»ºä¸´æ—¶è¾“å…¥æ¥æµ‹è¯•ç‰¹å¾ç»´åº¦
        # æ³¨æ„ï¼šéœ€è¦åœ¨evalæ¨¡å¼ä¸‹æµ‹è¯•ï¼Œé¿å…batch normç­‰é—®é¢˜
        self.global_backbone.eval()
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 224, 224)
            try:
                dummy_features = self.global_backbone(dummy_input)
                feature_dim = dummy_features.shape[1]  # [batch, feature_dim]
                print(f"æ£€æµ‹åˆ°çš„ç‰¹å¾ç»´åº¦: {feature_dim}")
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è‡ªåŠ¨æ£€æµ‹ç‰¹å¾ç»´åº¦: {e}")
                # ä½¿ç”¨é»˜è®¤å€¼ï¼ˆswin-tinyçš„embed_dimæ˜¯96ï¼‰
                feature_dim = 96
                print(f"ä½¿ç”¨é»˜è®¤ç‰¹å¾ç»´åº¦: {feature_dim}")
        self.global_backbone.train()
        
        # åˆ†ç±»å¤´
        self.global_classifier = nn.Linear(feature_dim, num_classes)
        self.local_classifier = nn.Linear(feature_dim, num_classes)
        
    def forward(self, full_image, local_image):
        # å…¨å±€è·¯å¾„
        global_features = self.global_backbone(full_image)
        global_logits = self.global_classifier(global_features)
        
        # å±€éƒ¨è·¯å¾„
        local_features = self.local_backbone(local_image)
        local_logits = self.local_classifier(local_features)
        
        return global_logits, local_logits, global_features, local_features


def load_all_json_files(data_dir: str) -> List[str]:
    """åŠ è½½æ‰€æœ‰JSONæ ‡æ³¨æ–‡ä»¶ï¼ˆè‡ªåŠ¨æœç´¢ï¼ŒKaggleé€‚é…ï¼‰"""
    json_files = []
    
    # æœç´¢è·¯å¾„åˆ—è¡¨ï¼ˆKaggleé€‚é…ï¼‰
    search_paths = [
        data_dir,
        BASE_DIR,
        WORKING_DIR,
    ]
    
    # æ·»åŠ æ‰€æœ‰è¾“å…¥æ•°æ®é›†è·¯å¾„
    if IN_KAGGLE:
        for dataset_name in os.listdir(INPUT_DIR):
            dataset_path = os.path.join(INPUT_DIR, dataset_name)
            if os.path.isdir(dataset_path):
                search_paths.append(dataset_path)
    
    # é¦–å…ˆå°è¯•ç›´æ¥è·¯å¾„
    for cls in CLASSES:
        found = False
        for search_path in search_paths:
            json_path = os.path.join(search_path, f'{cls}.json')
            if os.path.exists(json_path):
                json_files.append(json_path)
                found = True
                break
        
        if not found:
            # é€’å½’æœç´¢
            for search_path in search_paths:
                if os.path.exists(search_path):
                    pattern = os.path.join(search_path, '**', f'{cls}.json')
                    matches = glob.glob(pattern, recursive=True)
                    if matches:
                        json_files.append(matches[0])
                        found = True
                        break
        
        if not found:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ° {cls}.json")
    
    # å¦‚æœæ‰¾åˆ°äº†æ–‡ä»¶ï¼Œæ˜¾ç¤ºä½ç½®
    if json_files:
        print(f"\næ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
        for f in json_files:
            print(f"  - {f}")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½åœ¨åŒä¸€ç›®å½•
        dirs = [os.path.dirname(f) for f in json_files]
        if len(set(dirs)) == 1:
            print(f"\næ‰€æœ‰æ–‡ä»¶åœ¨åŒä¸€ç›®å½•: {dirs[0]}")
    
    return json_files


def compute_pairwise_loss(global_logits, local_logits, labels, 
                          global_features=None, local_features=None,
                          consistency_weight=0.5, feature_align_weight=0.1):
    """
    è®¡ç®—æˆå¯¹æŸå¤±å‡½æ•°
    
    Args:
        global_logits: å…¨å±€è·¯å¾„çš„logits [batch, num_classes]
        local_logits: å±€éƒ¨è·¯å¾„çš„logits [batch, num_classes]
        labels: çœŸå®æ ‡ç­¾ [batch]
        global_features: å…¨å±€ç‰¹å¾ [batch, feature_dim] (å¯é€‰)
        local_features: å±€éƒ¨ç‰¹å¾ [batch, feature_dim] (å¯é€‰)
        consistency_weight: ä¸€è‡´æ€§æŸå¤±æƒé‡
        feature_align_weight: ç‰¹å¾å¯¹é½æŸå¤±æƒé‡
    
    Returns:
        total_loss: æ€»æŸå¤±
        loss_dict: æŸå¤±å­—å…¸
    """
    # åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
    global_ce = F.cross_entropy(global_logits, labels)
    local_ce = F.cross_entropy(local_logits, labels)
    classification_loss = global_ce + local_ce
    
    # ä¸€è‡´æ€§æŸå¤±ï¼ˆKLæ•£åº¦ï¼‰
    global_probs = F.softmax(global_logits, dim=1)
    local_probs = F.softmax(local_logits, dim=1)
    
    # KL(global || local) + KL(local || global)
    consistency_loss = F.kl_div(
        F.log_softmax(global_logits, dim=1), 
        local_probs, 
        reduction='batchmean'
    ) + F.kl_div(
        F.log_softmax(local_logits, dim=1), 
        global_probs, 
        reduction='batchmean'
    )
    
    # ç‰¹å¾å¯¹é½æŸå¤±ï¼ˆå¦‚æœæä¾›äº†ç‰¹å¾ï¼‰
    feature_align_loss = torch.tensor(0.0, device=global_logits.device)
    if global_features is not None and local_features is not None:
        # L2è·ç¦»
        feature_align_loss = F.mse_loss(global_features, local_features)
    
    # æ€»æŸå¤±
    total_loss = (
        classification_loss + 
        consistency_weight * consistency_loss + 
        feature_align_weight * feature_align_loss
    )
    
    loss_dict = {
        'total': total_loss.item(),
        'classification': classification_loss.item(),
        'global_ce': global_ce.item(),
        'local_ce': local_ce.item(),
        'consistency': consistency_loss.item(),
        'feature_align': feature_align_loss.item()
    }
    
    return total_loss, loss_dict


def train_model(model, train_loader, val_loader, num_epochs=10, device='cuda',
                consistency_weight=0.5, feature_align_weight=0.1):
    """
    è®­ç»ƒåŒè·¯å¾„æ¨¡å‹ï¼ˆä½¿ç”¨æˆå¯¹æŸå¤±å‡½æ•°ï¼‰
    
    Args:
        model: åŒè·¯å¾„æ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        num_epochs: è®­ç»ƒè½®æ•°
        device: è®¾å¤‡
        consistency_weight: ä¸€è‡´æ€§æŸå¤±æƒé‡
        feature_align_weight: ç‰¹å¾å¯¹é½æŸå¤±æƒé‡
    """
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    
    train_losses = []
    val_losses = []
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_dict = {
            'total': 0.0,
            'classification': 0.0,
            'global_ce': 0.0,
            'local_ce': 0.0,
            'consistency': 0.0,
            'feature_align': 0.0
        }
        
        for batch in train_loader:
            # è·³è¿‡Noneæ ·æœ¬
            if batch is None:
                continue
            
            full_images = batch['full_image'].to(device)
            local_images = batch['local_image'].to(device)
            labels = batch['label'].to(device)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­ï¼ˆè·å–logitså’Œfeaturesï¼‰
            global_logits, local_logits, global_features, local_features = model(
                full_images, local_images
            )
            
            # è®¡ç®—æˆå¯¹æŸå¤±
            total_loss, loss_dict = compute_pairwise_loss(
                global_logits, local_logits, labels,
                global_features, local_features,
                consistency_weight=consistency_weight,
                feature_align_weight=feature_align_weight
            )
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            for key in train_loss_dict:
                train_loss_dict[key] += loss_dict[key]
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_dict = {
            'total': 0.0,
            'classification': 0.0,
            'global_ce': 0.0,
            'local_ce': 0.0,
            'consistency': 0.0,
            'feature_align': 0.0
        }
        
        with torch.no_grad():
            for batch in val_loader:
                # è·³è¿‡Noneæ ·æœ¬
                if batch is None:
                    continue
                
                full_images = batch['full_image'].to(device)
                local_images = batch['local_image'].to(device)
                labels = batch['label'].to(device)
                
                # å‰å‘ä¼ æ’­
                global_logits, local_logits, global_features, local_features = model(
                    full_images, local_images
                )
                
                # è®¡ç®—æŸå¤±
                _, loss_dict = compute_pairwise_loss(
                    global_logits, local_logits, labels,
                    global_features, local_features,
                    consistency_weight=consistency_weight,
                    feature_align_weight=feature_align_weight
                )
                
                for key in val_loss_dict:
                    val_loss_dict[key] += loss_dict[key]
        
        # è®¡ç®—å¹³å‡æŸå¤±
        num_batches = len(train_loader)
        for key in train_loss_dict:
            train_loss_dict[key] /= num_batches
        
        num_val_batches = len(val_loader)
        for key in val_loss_dict:
            val_loss_dict[key] /= num_val_batches
        
        train_losses.append(train_loss_dict['total'])
        val_losses.append(val_loss_dict['total'])
        
        # æ‰“å°æŸå¤±ä¿¡æ¯
        print(f'\nEpoch [{epoch+1}/{num_epochs}]')
        print(f'  Train Loss: {train_loss_dict["total"]:.4f}')
        print(f'    - Classification: {train_loss_dict["classification"]:.4f} '
              f'(Global CE: {train_loss_dict["global_ce"]:.4f}, '
              f'Local CE: {train_loss_dict["local_ce"]:.4f})')
        print(f'    - Consistency: {train_loss_dict["consistency"]:.4f}')
        print(f'    - Feature Align: {train_loss_dict["feature_align"]:.4f}')
        print(f'  Val Loss: {val_loss_dict["total"]:.4f}')
        print(f'    - Classification: {val_loss_dict["classification"]:.4f} '
              f'(Global CE: {val_loss_dict["global_ce"]:.4f}, '
              f'Local CE: {val_loss_dict["local_ce"]:.4f})')
        print(f'    - Consistency: {val_loss_dict["consistency"]:.4f}')
        print(f'    - Feature Align: {val_loss_dict["feature_align"]:.4f}')
    
    return train_losses, val_losses


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("åŒè·¯å¾„é±¼ç±»åˆ†ç±»æ¨¡å‹ - Kaggleç‰ˆæœ¬")
    print("=" * 60)
    
    # Kaggleç¯å¢ƒä¸‹çš„æ•°æ®ç›®å½•æŸ¥æ‰¾
    if IN_KAGGLE:
        print("\nğŸ” åœ¨Kaggleç¯å¢ƒä¸­æŸ¥æ‰¾æ•°æ®...")
        
        # åˆ—å‡ºæ‰€æœ‰è¾“å…¥æ•°æ®é›†
        print(f"\nè¾“å…¥æ•°æ®é›†åˆ—è¡¨ ({INPUT_DIR}):")
        datasets = []
        for item in os.listdir(INPUT_DIR):
            item_path = os.path.join(INPUT_DIR, item)
            if os.path.isdir(item_path):
                datasets.append(item)
                print(f"  ğŸ“ {item}")
        
        # å°è¯•åœ¨æ¯ä¸ªæ•°æ®é›†ä¸­æŸ¥æ‰¾JSONæ–‡ä»¶
        data_dir = None
        for dataset_name in datasets:
            dataset_path = os.path.join(INPUT_DIR, dataset_name)
            json_test = load_all_json_files(dataset_path)
            if json_test:
                data_dir = dataset_path
                print(f"\nâœ… åœ¨æ•°æ®é›† '{dataset_name}' ä¸­æ‰¾åˆ°JSONæ–‡ä»¶")
                break
        
        if data_dir is None:
            # å°è¯•åœ¨å·¥ä½œç›®å½•æŸ¥æ‰¾
            print("\nåœ¨å·¥ä½œç›®å½•ä¸­æŸ¥æ‰¾...")
            json_test = load_all_json_files(WORKING_DIR)
            if json_test:
                data_dir = WORKING_DIR
            else:
                print("âš ï¸  æœªæ‰¾åˆ°JSONæ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ•°æ®é›†å·²æ·»åŠ åˆ°Notebook Input")
                print("\næç¤º:")
                print("1. åœ¨Kaggle Notebookä¸­ï¼Œç‚¹å‡»å³ä¾§ 'Add Input'")
                print("2. é€‰æ‹©åŒ…å«JSONæ–‡ä»¶çš„æ•°æ®é›†")
                print("3. JSONæ–‡ä»¶åº”è¯¥åœ¨ /kaggle/input/dataset-name/ ç›®å½•ä¸‹")
                return
    else:
        # æœ¬åœ°ç¯å¢ƒ
        data_dir = os.path.dirname(os.path.abspath(__file__))
        print(f"\næœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ç›®å½•: {data_dir}")
    
    # åˆ†ææ•°æ®é›†ï¼ˆè‡ªåŠ¨æœç´¢JSONæ–‡ä»¶ï¼‰
    json_files = load_all_json_files(data_dir)
    if not json_files:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•JSONæ–‡ä»¶ï¼")
        if IN_KAGGLE:
            print("\nè¯·ç¡®ä¿:")
            print("1. æ•°æ®é›†å·²æ·»åŠ åˆ°Notebookçš„Inputä¸­")
            print("2. JSONæ–‡ä»¶åœ¨æ•°æ®é›†çš„æ ¹ç›®å½•æˆ–å­ç›®å½•ä¸­")
            print("3. JSONæ–‡ä»¶å‘½åæ­£ç¡®ï¼ˆALB.json, BET.jsonç­‰ï¼‰")
        return
    
    print(f"\nâœ… æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    # å®šä¹‰å›¾åƒå˜æ¢
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    print("\n" + "=" * 60)
    print("åˆ›å»ºæ•°æ®é›†")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®é›†ï¼Œè·³è¿‡ç¼ºå¤±çš„å›¾ç‰‡
    full_dataset = FishDataset(
        data_dir, 
        json_files, 
        transform=transform, 
        expand_ratio=0.2,
        skip_missing=True  # è·³è¿‡ç¼ºå¤±çš„å›¾ç‰‡
    )
    
    print(f"æ•°æ®é›†å¤§å°: {len(full_dataset)} ä¸ªæ ·æœ¬")
    if len(full_dataset) == 0:
        print("\nâš ï¸  è­¦å‘Š: æ‰€æœ‰å›¾ç‰‡éƒ½æ‰¾ä¸åˆ°ï¼")
        if IN_KAGGLE:
            print("è¯·æ£€æŸ¥:")
            print("1. å›¾ç‰‡æ–‡ä»¶æ˜¯å¦åœ¨æ•°æ®é›†ä¸­")
            print("2. å›¾ç‰‡è·¯å¾„æ˜¯å¦ä¸JSONä¸­çš„è·¯å¾„åŒ¹é…")
            print("3. å›¾ç‰‡æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        return
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    batch_size = 16
    num_workers = 0  # Kaggleä¸­å»ºè®®ä½¿ç”¨0
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\n" + "=" * 60)
    print("åˆ›å»ºåŒè·¯å¾„æ¨¡å‹")
    print("=" * 60)
    print("æ¶æ„:")
    print("  å…¨å±€è·¯å¾„: Full Image -> Swin Backbone -> Global Feature -> Classification -> CE(global)")
    print("  å±€éƒ¨è·¯å¾„: BBox Crop Image (expand 20%) -> Swin Backbone -> Local Feature -> Classification -> CE(local)")
    print("  æœ€ç»ˆæŸå¤±: Final Loss = CE(global) + CE(local) + Consistency + Feature Align")
    
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name(0)}")
    
    model = DualPathModel(num_classes=NUM_CLASSES).to(device)
    
    # è®­ç»ƒæ¨¡å‹
    print("\n" + "=" * 60)
    print("å¼€å§‹è®­ç»ƒï¼ˆä½¿ç”¨æˆå¯¹æŸå¤±å‡½æ•°ï¼‰")
    print("=" * 60)
    print("æŸå¤±å‡½æ•°ç»„æˆ:")
    print("  - åˆ†ç±»æŸå¤±: CE(global) + CE(local)")
    print("  - ä¸€è‡´æ€§æŸå¤±: KLæ•£åº¦ç¡®ä¿å…¨å±€å’Œå±€éƒ¨é¢„æµ‹ä¸€è‡´")
    print("  - ç‰¹å¾å¯¹é½æŸå¤±: è®©å…¨å±€å’Œå±€éƒ¨ç‰¹å¾åœ¨ç‰¹å¾ç©ºé—´ä¸­æ›´æ¥è¿‘")
    print("  - æœ€ç»ˆæŸå¤± = åˆ†ç±»æŸå¤± + 0.5 * ä¸€è‡´æ€§æŸå¤± + 0.1 * ç‰¹å¾å¯¹é½æŸå¤±")
    
    train_losses, val_losses = train_model(
        model, train_loader, val_loader, 
        num_epochs=10, device=device,
        consistency_weight=0.5,  # ä¸€è‡´æ€§æŸå¤±æƒé‡
        feature_align_weight=0.1  # ç‰¹å¾å¯¹é½æŸå¤±æƒé‡
    )
    
    # ä¿å­˜æ¨¡å‹ï¼ˆä¿å­˜åˆ°å·¥ä½œç›®å½•ï¼‰
    model_path = os.path.join(WORKING_DIR, 'dual_path_model.pth')
    torch.save(model.state_dict(), model_path)
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Dual Path Model Training Loss')
    plt.legend()
    plt.grid(True)
    loss_plot_path = os.path.join(WORKING_DIR, 'training_loss.png')
    plt.savefig(loss_plot_path)
    print(f"âœ… è®­ç»ƒæŸå¤±æ›²çº¿å·²ä¿å­˜åˆ°: {loss_plot_path}")
    
    print("\n" + "=" * 60)
    print("è®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    if IN_KAGGLE:
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
        print(f"  - æ¨¡å‹: {model_path}")
        print(f"  - æŸå¤±æ›²çº¿: {loss_plot_path}")
        print("\nğŸ’¡ æç¤º: è¿™äº›æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åˆ°Kaggle Notebookçš„è¾“å‡ºä¸­")


if __name__ == '__main__':
    main()

